{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397ec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "from torch_geometric.data import DataLoader, Dataset, Data\n",
    "import lightning.pytorch as pl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import itertools\n",
    "import yaml\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from epic_clustering.utils import plot_clusters, get_cluster_pos\n",
    "from epic_clustering.models import MemberClassification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9176da3",
   "metadata": {},
   "source": [
    "## 1. Load Model and Test Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7452aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/global/cfs/cdirs/m3443/data/PowerWeek/train/train\"\n",
    "csv_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e23e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_csv(csv_files[0])\n",
    "event = events[events[\"event\"] == events[\"event\"].unique()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted event.E - get first 40\n",
    "high_energy_hits = event.sort_values(by=\"E\", ascending=False).iloc[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6ff51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use torch meshgrid to get all pairs between high_energy_hits.hit_number and event.hit_number\n",
    "pairs = torch.meshgrid(torch.from_numpy(high_energy_hits.hit_number.values), torch.from_numpy(event.hit_number.values))\n",
    "# convert into a 2 x N array\n",
    "pairs = torch.stack(pairs).reshape(2, -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5cd2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventDataset(Dataset):\n",
    "    \"\"\"\n",
    "    The custom default dataset to load CSV events off the disk\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dir, num_events = None, hparams=None, transform=None, pre_transform=None, pre_filter=None, **kwargs):\n",
    "        super().__init__(input_dir, transform, pre_transform, pre_filter)\n",
    "        \n",
    "        self.input_dir = input_dir\n",
    "        self.hparams = hparams\n",
    "        self.num_events = num_events\n",
    "        self.scales = {\n",
    "                    \"E\": 30.,\n",
    "                    \"T\": 100.,\n",
    "                    \"posx\": 200.,\n",
    "                    \"posy\": 200.,\n",
    "                    \"posz\": 500.,\n",
    "                }\n",
    "        \n",
    "        self.csv_events = self.load_datafiles_in_dir(self.input_dir, self.num_events)\n",
    "\n",
    "        print(\"Converting to PyG data objects\")\n",
    "        self.pyg_events = [self.convert_to_pyg(event[1]) for event in tqdm(self.csv_events)]\n",
    "        \n",
    "    def load_datafiles_in_dir(self, input_dir, num_events):\n",
    "\n",
    "        # Each file is 1000 events, so need to load num_events//1000 + 1 files\n",
    "        csv_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.csv')][:num_events//1000 + 1]\n",
    "        events = pd.concat([pd.read_csv(f) for f in csv_files])\n",
    "        if num_events is not None:\n",
    "            events = events[events.entry < num_events]\n",
    "\n",
    "        self.scale_features(events)\n",
    "\n",
    "        return list(events.groupby('entry'))\n",
    "\n",
    "    def convert_to_pyg(self, event):\n",
    "\n",
    "        # Convert to PyG data object\n",
    "        event = event.reset_index(drop=True)\n",
    "        event = event.drop(columns=['entry'])\n",
    "\n",
    "        data.edge_index = self.create_training_pairs(event)\n",
    "        y = event.clusterID[data.edge_index[0]] == event.clusterID[data.edge_index[1]]\n",
    "        node_features = torch.from_numpy(event[['posx', 'posy', 'posz', 'E']].to_numpy())\n",
    "        edge_features = torch.cat([node_features[data.edge_index[0]], node_features[data.edge_index[1]]], dim=1)\n",
    "\n",
    "        data = Data(\n",
    "                        x = edge_features,\n",
    "                        y = y\n",
    "                    )\n",
    "\n",
    "        data.num_nodes = data.x.shape[0]\n",
    "\n",
    "        return data\n",
    "        \n",
    "    def len(self):\n",
    "        return len(self.pyg_events)\n",
    "\n",
    "    def get(self, idx):\n",
    "\n",
    "        return self.pyg_events[idx]\n",
    "\n",
    "    def scale_features(self, event):\n",
    "        \"\"\"\n",
    "        Handle feature scaling for the event\n",
    "        \"\"\"\n",
    "\n",
    "        for feature in self.scales.keys():\n",
    "            event[feature] = event[feature]/self.scales[feature]\n",
    "\n",
    "        return event\n",
    "\n",
    "    def create_training_pairs(self, event):\n",
    "        \"\"\"\n",
    "        Create the true edge list for the event. This is \n",
    "        \"\"\"\n",
    "\n",
    "        # Sorted event.E - get first 40\n",
    "        high_energy_hits = event.sort_values(by=\"E\", ascending=False).iloc[:40]\n",
    "\n",
    "        # use torch meshgrid to get all pairs between high_energy_hits.hit_number and event.hit_number\n",
    "        pairs = torch.meshgrid(torch.from_numpy(high_energy_hits.hit_number.values), torch.from_numpy(event.hit_number.values))\n",
    "        # convert into a 2 x N array\n",
    "        pairs = torch.stack(pairs).reshape(2, -1)\n",
    "\n",
    "        return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4629039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EventDataset(input_dir, num_events=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ca1815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train val and test\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c6ab1ee",
   "metadata": {},
   "source": [
    "## 3. Training Loop Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae4c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"member_classification.yaml\") as f:\n",
    "    member_classification_config = yaml.safe_load(f)\n",
    "model = MemberClassification(member_classification_config)\n",
    "model.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd53e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = WandbLogger(project=member_classification_config[\"project\"])\n",
    "trainer = pl.Trainer(devices=1, accelerator=\"gpu\", max_epochs=100, logger=logger)\n",
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PowerWeek",
   "language": "python",
   "name": "powerweek"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
